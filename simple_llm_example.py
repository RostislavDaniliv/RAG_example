import os
from dotenv import load_dotenv
from langchain_openai import OpenAI
from langchain_openai import ChatOpenAI

load_dotenv()

def demonstrate_without_rag():
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.9)
    
    questions = [
        "–°–∫—ñ–ª—å–∫–∏ –¥–Ω—ñ–≤ –≤—ñ–¥–ø—É—Å—Ç–∫–∏ –º–∞—î —Å–ø—ñ–≤—Ä–æ–±—ñ—Ç–Ω–∏–∫ —É –∫–æ–º–ø–∞–Ω—ñ—ó?",
        "–Ø–∫ –ø—Ä–∞—Ü—é—é—Ç—å –ø—Ä–µ–º—ñ—ó –≤ –∫–æ–º–ø–∞–Ω—ñ—ó GoWombat?"
    ]
    
    for question in questions:
        print(f"\n‚ùì Query: {question}")
        response = llm.invoke(question)
        print(f"ü§ñ Answer: {response.content}")
        print("-" * 50)

if __name__ == "__main__":
    if not os.getenv("OPENAI_API_KEY"):
        print("Error: Set OPENAI_API_KEY in .env file")
    else:
        demonstrate_without_rag()
